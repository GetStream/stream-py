[project]
name = "llm-audio-conversation-example"
version = "0.1.0"
description = "Example project showing how to integrate speech-to-text, text-to-speech and an LLM."
readme = "README.md"
requires-python = ">=3.9"
license = {text = "MIT"}

dependencies = [
    "getstream[webrtc]",
    "getstream-plugins-stt-deepgram",
    "getstream-plugins-tts-elevenlabs",
    "getstream-plugins-vad-silero",
    "python-dotenv>=1.0.0",
    "aiortc>=1.10.1",
    "numpy>=2.0.0",
    "openai>=1.82.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-asyncio>=0.21.0",
]

[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[tool.uv.sources]
getstream = { workspace = true }
getstream-plugins-stt-deepgram = { workspace = true }
getstream-plugins-tts-elevenlabs = { workspace = true }
getstream-plugins-vad-silero = { workspace = true }
