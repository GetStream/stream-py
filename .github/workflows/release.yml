name: Release

on:
  pull_request:
    types: [closed]
    branches:
      - main
  workflow_dispatch:
    inputs:
      python-version:
        description: "Python version to use"
        default: "3.12"
        required: false

permissions:
  contents: read
  id-token: write

jobs:
  build-core:
    name: Build & Test Core SDK
    if: (github.event.pull_request.merged && startsWith(github.head_ref, 'release-')) || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    environment: ci
    outputs:
      version: ${{ steps.get_version.outputs.version }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install uv and set the python version
        uses: astral-sh/setup-uv@v5
        with:
          python-version: ${{ github.event.inputs.python-version || '3.12' }}

      - name: Sync environment & install dev extras
        run: |
          uv sync --all-packages --all-extras --dev --all-groups

      - name: Build core distributions
        run: |
          uv build -o dist

      - name: Extract package version
        id: get_version
        run: |
          python - <<'PY'
          import re, os, pathlib, sys
          version_file = pathlib.Path('getstream') / 'version.py'
          content = version_file.read_text()
          match = re.search(r"VERSION\s*=\s*['\"]([^'\"]+)['\"]", content)
          if not match:
              sys.exit('Could not find VERSION in getstream/version.py')
          version = match.group(1)
          with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
              fh.write(f'version={version}\n')
          PY

      - name: Publish core to PyPI
        env:
          TWINE_USERNAME: __token__
          TWINE_PASSWORD: ${{ secrets.PYPI_API_TOKEN }}
        run: |
          uv pip install --upgrade twine
          for FILE in dist/getstream*.whl; do
            BASENAME=$(basename "$FILE")
            PACKAGE_NAME=${BASENAME%%-*}
            VERSION=$(echo "$BASENAME" | cut -d'-' -f2) # 1.5.0a2 etc.
            echo "Checking if $PACKAGE_NAME version $VERSION exists on PyPI..."
            if pip index versions --pre "$PACKAGE_NAME" | grep -q "$VERSION"; then
              echo "Version $VERSION already exists for $PACKAGE_NAME â€“ skipping upload."
            else
              echo "Uploading $BASENAME to PyPI."
              twine upload "$FILE"
            fi
          done

      - name: Install core from using uv
        run: |
          uv pip install "getstream==${{ steps.get_version.outputs.version }}"

      - name: Run core tests against PyPI artifact
        env:
          STREAM_BASE_URL: ${{ vars.STREAM_BASE_URL }}
          STREAM_API_KEY: ${{ vars.STREAM_API_KEY }}
          STREAM_API_SECRET: ${{ secrets.STREAM_API_SECRET }}
        run: |
          UV_NO_SOURCES=1 uv run pytest --ignore=getstream/plugins

  build-plugins:
    name: Build & Test Plugin Packages
    runs-on: ubuntu-latest
    needs: build-core
    environment: ci
    env:
      CORE_VERSION: ${{ needs.build-core.outputs.version }}
      UV_NO_SOURCES: "1"
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install uv and set the python version
        uses: astral-sh/setup-uv@v5
        with:
          python-version: ${{ github.event.inputs.python-version || '3.12' }}

      - name: Install new core from PyPI using uv (for plugin builds/tests)
        run: |
          uv pip install "getstream==${CORE_VERSION}"

      - name: Detect updated plugins
        id: detect
        shell: bash
        run: |
          set -e
          declare -a UPD_PKG UPD_DIR
          for dir in getstream/plugins/*/; do
            [[ -f "$dir/pyproject.toml" ]] || continue
            # get "name version" from pyproject.toml in one shot
            read -r name ver <<<"$(python -c 'import tomllib,sys, pathlib; p=sys.argv[1]; data=tomllib.load(open(p,"rb")); print(data["project"]["name"], data["project"]["version"])' "$dir/pyproject.toml")"
            if ! pip index versions --pre "$name" | grep -q "$ver"; then
              UPD_PKG+=("$name")
              UPD_DIR+=("${dir%/}")
            fi
          done
          echo "updated_packages=${UPD_PKG[*]}"   >>"$GITHUB_OUTPUT"
          echo "updated_dirs=${UPD_DIR[*]}"       >>"$GITHUB_OUTPUT"
          [[ ${#UPD_PKG[@]} -gt 0 ]] && echo "has_updates=true" >>"$GITHUB_OUTPUT"

      - name: Build wheels
        if: steps.detect.outputs.has_updates == 'true'
        run: |
          mkdir -p dist-plugins
          for pkg in ${{ steps.detect.outputs.updated_packages }}; do
            echo "::group::Building $pkg"
            uv build --package "$pkg" -o dist-plugins --wheel --sdist
            echo "::endgroup::"
          done

      - name: Test updated plugins (local wheels)
        if: steps.detect.outputs.has_updates == 'true'
        env:
          STREAM_BASE_URL:   ${{ vars.STREAM_BASE_URL }}
          STREAM_API_KEY:    ${{ vars.STREAM_API_KEY }}
          STREAM_API_SECRET: ${{ secrets.STREAM_API_SECRET }}
        run: |
          uv pip install dist-plugins/*.whl
          uv run pytest ${{ steps.detect.outputs.updated_dirs }}

      - name: Publish wheels to PyPI
        if: steps.detect.outputs.has_updates == 'true'
        env:
          TWINE_USERNAME: __token__
          TWINE_PASSWORD: ${{ secrets.PYPI_API_TOKEN }}
        run: |
          uv pip install --upgrade twine
          twine upload dist-plugins/*.whl

      - name: Re-install from PyPI and re-run tests
        if: steps.detect.outputs.has_updates == 'true'
        run: |
          uv pip install "getstream==${CORE_VERSION}" ${{ steps.detect.outputs.updated_packages }}
          uv run pytest ${{ steps.detect.outputs.updated_dirs }}
